---
title: paper-44
layout: page
---
<head>
<style>
div1 {
  background-color: lightgrey;
  width: 30px;
  border: 1px solid green;
  padding: 5px;
  margin: 1px;
}
.button {
  border: none;
  color: white;
  padding: 6px 6px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 16px;
  margin: 4px 2px;
  transition-duration: 0.4s;
  cursor: pointer;
}.button1 {
  background-color: white; 
  color: black; 
  border: 2px solid #008CBA;
}
.button1:hover {
  background-color: #008CBA;
  color: white;
}.button2 {
  background-color: white;
  color: black; 
  border: 2px solid red;
}
.button2:hover {
  background-color: red;
  color: white;
}
</style>
</head>
<div class='container'>
  <div class='row'>
      <div class='3u 12u(mobile)'>
      <section>
       <button class='button button2' onclick=" window.open('https://ojs.aaai.org/index.php/ICAPS/article/view/19822/19581','_blank')"><input type='image' src='../../images/hyperlink-logo.png' width='14' height='13'> PDF</button>
<br><br><h3 class='top'>Talk Sessions: </h3>
<button class='button button1' onclick=" window.open('http://icaps22.icaps-conference.org/schedule#1b','_blank')"><input type='image' src='../../images/hyperlink-blue.png' width='14' height='13'>June 21, Session 1b</button>
<button class='button button1' onclick=" window.open('http://icaps22.icaps-conference.org/schedule#12b','_blank')"><input type='image' src='../../images/hyperlink-blue.png' width='14' height='13'>June 22, Session 12b</button>
<br><br><h3 class='top'>Poster Sessions: </h3>
<button class='button button2' onclick=" window.open('http://icaps22.icaps-conference.org/posters/ICAPS_2022_paper_44_poster-neural_network_action_policy_verification_via_predicate_abstraction.pdf','_blank')"><input type='image' src='../../images/hyperlink-logo.png' width='14' height='13'> Poster</button><br><br>
<div1> June 21, Booth 8</div1> <br><br>
<div1> June 22, Booth 5</div1> <br><br>
</section>
 </div>
<div class='9u 12u(mobile)'>
    <section>
      <header>
        <h1 class='top'>Neural Network Action Policy Verification via Predicate Abstraction</h1>
        <h3>Marcel Vinzent, Marcel Steinmetz and JÃ¶rg Hoffmann</h3>
      </header>
<b>Abstract:</b> Neural networks (NN) are an increasingly important representation of action policies. Verifying that such policies are safe is potentially very hard as it compounds the state space explosion with the difficulty of analyzing even single NN decision episodes. Here we address that challenge through abstract reachability analysis. We show how to compute predicate abstractions of the policy state space subgraph induced by fixing an NN action policy. A key sub-problem here is the computation of abstract state transitions that may be taken by the policy, which as we show can be tackled by connecting to off-the-shelf SMT solvers. We devise a range of algorithmic enhancements, leveraging relaxed tests to avoid costly calls to SMT. We empirically evaluate the resulting machinery on a collection of benchmarks. The results show that our enhancements are required for practicality, and that our approach can outperform two competing approaches based on explicit enumeration and bounded-length verification.
</section>
  </div>
  </div>
</div>