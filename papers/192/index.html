---
title: paper-192
layout: page
---
<head>
<style>
div1 {
  background-color: lightgrey;
  width: 30px;
  border: 1px solid green;
  padding: 5px;
  margin: 1px;
}
.button {
  border: none;
  color: white;
  padding: 6px 6px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 16px;
  margin: 4px 2px;
  transition-duration: 0.4s;
  cursor: pointer;
}.button1 {
  background-color: white; 
  color: black; 
  border: 2px solid #008CBA;
}
.button1:hover {
  background-color: #008CBA;
  color: white;
}.button2 {
  background-color: white;
  color: black; 
  border: 2px solid red;
}
.button2:hover {
  background-color: red;
  color: white;
}
</style>
</head>
<div class='container'>
  <div class='row'>
      <div class='3u 12u(mobile)'>
      <section>
       <button class='button button2' onclick=" window.open('https://ojs.aaai.org/index.php/ICAPS/article/view/19861/19620','_blank')"><input type='image' src='../../images/hyperlink-logo.png' width='14' height='13'> PDF</button>
<br><br><h3 class='top'>Talk Sessions: </h3>
<button class='button button1' onclick=" window.open('http://icaps22.icaps-conference.org/schedule#15b','_blank')"><input type='image' src='../../images/hyperlink-blue.png' width='14' height='13'>June 22, Session 15b</button>
<button class='button button1' onclick=" window.open('http://icaps22.icaps-conference.org/schedule#20a','_blank')"><input type='image' src='../../images/hyperlink-blue.png' width='14' height='13'>June 23, Session 20a</button>
<br><br><h3 class='top'>Poster Sessions: </h3>
<button class='button button2' onclick=" window.open('http://icaps22.icaps-conference.org/posters/Poster_ICAPS2022_express.pdf','_blank')"><input type='image' src='../../images/hyperlink-logo.png' width='14' height='13'> Poster</button><br><br>
<div1> June 22, Booth 26</div1> <br><br>
<div1> June 23, Booth 29</div1> <br><br>
</section>
 </div>
<div class='9u 12u(mobile)'>
    <section>
      <header>
        <h1 class='top'>Explaining Preference-driven Schedules: the EXPRES Framework</h1>
        <h3>Alberto Pozanco, Francesca Mosca, Parisa Zehtabi, Daniele Magazzeni and Sarit Kraus</h3>
      </header>
<b>Abstract:</b> Scheduling is the task of assigning a set of scarce resources distributed over time to a set of agents, who typically have preferences over the assignments they would like to get.
Due to the constrained nature of these problems, satisfying all agents' preferences often turns infeasible, which might lead to some agents not being happy with the resulting schedule.
Providing explanations has been shown to increase satisfaction and trust in solutions produced by AI tools.
However, explaining schedules poses some particular challenges such as problem interpretability (i.e., generating explanations from a huge and dense amount of information) and privacy preservation (i.e., generating explanations respecting the privacy of other agents involved). 
In this paper we introduce the EXPRES framework, that can explain why a given preference was unsatisfied in a given optimal schedule. The EXPRES framework consists of (i) an explanation generator, that, based on a Mixed-Integer Linear Programming model, finds the best set of reasons that can explain an unsatisfied preference; and (ii) an explanation parser, which translates the generated explanations into human interpretable ones, while preserving agents' privacy.
Through simulations, we show that the explanation generator can efficiently scale to large instances.
Finally, through a set of user studies within J.P. Morgan, we show that employees preferred the explanations generated by EXPRES over human-generated ones when considering workforce scheduling scenarios.
</section>
  </div>
  </div>
</div>