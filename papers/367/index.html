---
title: paper-367
layout: page
---
<head>
<style>
div1 {
  background-color: lightgrey;
  width: 30px;
  border: 1px solid green;
  padding: 5px;
  margin: 1px;
}
.button {
  border: none;
  color: white;
  padding: 6px 6px;
  text-align: center;
  text-decoration: none;
  display: inline-block;
  font-size: 16px;
  margin: 4px 2px;
  transition-duration: 0.4s;
  cursor: pointer;
}.button1 {
  background-color: white; 
  color: black; 
  border: 2px solid #008CBA;
}
.button1:hover {
  background-color: #008CBA;
  color: white;
}.button2 {
  background-color: white;
  color: black; 
  border: 2px solid red;
}
.button2:hover {
  background-color: red;
  color: white;
}
</style>
</head>
<div class='container'>
  <div class='row'>
      <div class='3u 12u(mobile)'>
      <section>
       <button class='button button2' onclick=" window.open('https://www.jair.org/index.php/jair/article/view/12813','_blank')"><input type='image' src='../../images/hyperlink-logo.png' width='14' height='13'> PDF</button>
<br><br><h3 class='top'>Talk Sessions: </h3>
<button class='button button1' onclick=" window.open('http://icaps22.icaps-conference.org/schedule#20a','_blank')"><input type='image' src='../../images/hyperlink-blue.png' width='14' height='13'>June 23, Session 20a</button>
<button class='button button1' onclick=" window.open('http://icaps22.icaps-conference.org/schedule#31a','_blank')"><input type='image' src='../../images/hyperlink-blue.png' width='14' height='13'>June 24, Session 31a</button>
<br><br><h3 class='top'>Poster Sessions: </h3>
<button class='button button2' onclick=" window.open('http://icaps22.icaps-conference.org/posters/ICAPSJournalPoster.pdf','_blank')"><input type='image' src='../../images/hyperlink-logo.png' width='14' height='13'> Poster</button><br><br>
<div1> June 23, Booth 49</div1> <br><br>
<div1> June 24, Booth 34</div1> <br><br>
</section>
 </div>
<div class='9u 12u(mobile)'>
    <section>
      <header>
        <h1 class='top'>Contrastive Explanations of Plans Through Model Restrictions</h1>
        <h3>Benjamin Krarup, Senka Krivic, Daniele Magazzeni, Derek Long, Michael Cashmore and David E. Smith</h3>
      </header>
<b>Abstract:</b> In automated planning, the need for explanations arises when there is a mismatch between a proposed plan and the user√ïs expectation. We frame Explainable AI Planning as an iterative plan exploration process, in which the user asks a succession of contrastive questions that lead to the generation and solution of hypothetical planning problems that are restrictions of the original problem. The object of the exploration is for the user to understand the constraints that govern the original plan and, ultimately, to arrive at a satisfactory plan.

We present the results of a user study that demonstrates that when users ask questions about plans, those questions are usually contrastive, i.e. "why A rather than B?". We use the data from this study to construct a taxonomy of user questions that often arise during plan exploration.

Our approach to iterative plan exploration is a process of successive model restriction. Each contrastive user question imposes a set of constraints on the planning problem, leading to the construction of a new hypothetical planning problem as a restriction of the original. Solving this restricted problem results in a plan that can be compared with the original plan, admitting a contrastive explanation.

We formally define model-based compilations in PDDL2.1 for each type of constraint derived from a contrastive user question in the taxonomy, and empirically evaluate the compilations in terms of computational complexity.

The compilations were implemented as part of an explanation framework supporting iterative model restriction. We demonstrate its benefits in a second user study.
</section>
  </div>
  </div>
</div>